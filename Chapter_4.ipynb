{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHOgnbSufBWewWuQ2yR30f"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1"
      ],
      "metadata": {
        "id": "OjgfBiuKB7wm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$A=e^{\\beta_0+\\beta_1X}$\n",
        "\n",
        "$p(X)=\\frac{e^{\\beta_0+\\beta_1X}}{1+e^{\\beta_0+\\beta_1X}}$\n",
        "\n",
        "$p(X)=\\frac{A}{1+A}$\n",
        "\n",
        "$\\frac{p(X)}{1-p(X)}=\\frac{\\frac{A}{1+A}}{1-\\frac{A}{1+A}}$\n",
        "\n",
        "$\\frac{p(X)}{1-p(X)}=\\frac{\\frac{A}{1+A}*(1+A)}{1+A-A}$\n",
        "\n",
        "$\\frac{p(X)}{1-p(X)}=\\frac{A}{1}$\n",
        "\n",
        "$\\frac{p(X)}{1-p(X)}=e^{\\beta_0+\\beta_1X}$"
      ],
      "metadata": {
        "id": "59St7CdUCB68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2"
      ],
      "metadata": {
        "id": "Uy0lsPP2Gm3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are interested in find the class $k$ which maximizes $p_k(x)$. We have:\n",
        "\n",
        "$p_k(x)=\\frac{\\frac{\\pi_k}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\pi_k)^2}{2\\sigma^2}}}{\\sum_{l=1}^{K}{\\frac{\\pi_l}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\pi_l)^2}{2\\sigma^2}}}}$\n",
        "\n",
        "Since the denominator is the same for every $k$, to maximize $p(x)$, we are only concerned in maximizing the numerator. Apply the log to the numerator, we have:\n",
        "\n",
        "$log(\\frac{\\pi_k}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\pi_k)^2}{2\\sigma^2}})=log(\\pi_k)-log(\\sqrt{2\\pi}\\sigma)-\\frac{(x-\\pi_k)^2}{2\\sigma^2}$\n",
        "\n",
        "Once again, the term $log(\\sqrt{2\\pi}\\sigma)$ is a constant. Therefore, it does not depend on the class $k$. Expanding the last term, we have:\n",
        "\n",
        "$log(\\pi_k)-\\frac{x^2-2\\pi_kx+\\pi_k^2}{2\\sigma^2}=$\n",
        "\n",
        "Since the value of $x$ if not affected by the class, we end up with:\n",
        "\n",
        "$log(\\pi_k)+\\frac{\\pi_kx}{\\sigma^2}-\\frac{\\pi_k^2}{2\\sigma^2}$\n",
        "\n"
      ],
      "metadata": {
        "id": "Zn2iLqfkGogL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3"
      ],
      "metadata": {
        "id": "82mMKVLATrs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly to the LDA, the denominator of $p(x)$ is constant in QDA. The only difference is that we now have a specific variance for each class. Therefore, we have:\n",
        "\n",
        "$log(\\frac{\\pi_k}{\\sqrt{2\\pi}\\sigma_k}e^{-\\frac{(x-\\pi_k)^2}{2\\sigma_k^2}})=log(\\pi_k)-log(\\sqrt{2\\pi}\\sigma_k)-\\frac{(x-\\pi_k)^2}{2\\sigma_k^2}$\n",
        "\n",
        "Expanding, we have:\n",
        "\n",
        "$log(\\pi_k)-log(\\sqrt{2\\pi}\\sigma_k)-\\frac{x^2-2\\pi_kx+\\pi_k^2}{2\\sigma_k^2}$\n",
        "\n",
        "We end up with:\n",
        "\n",
        "$log(\\pi_k)-log(\\sqrt{2\\pi}\\sigma_k)-\\frac{x^2}{2\\sigma^2_k}+\\frac{\\pi_kx}{\\sigma_k^2}-\\frac{\\pi_k^2}{2\\sigma_k^2}$"
      ],
      "metadata": {
        "id": "_UonpXOzTtZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4"
      ],
      "metadata": {
        "id": "qcnkDu5ZWO6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a)"
      ],
      "metadata": {
        "id": "p1MXi3kxWQog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10%."
      ],
      "metadata": {
        "id": "xy20LID4WX8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b)"
      ],
      "metadata": {
        "id": "jN5J0hBYWawO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1%."
      ],
      "metadata": {
        "id": "GdgBj_A3Wca-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c)"
      ],
      "metadata": {
        "id": "OtFPbL-pWdq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practically 0%."
      ],
      "metadata": {
        "id": "hdVfhpXSWfX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d)"
      ],
      "metadata": {
        "id": "Q775nmi_WmD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The KNN performance deteriorates exponeantially as the number of predictors, and therefore the dimensionality increases."
      ],
      "metadata": {
        "id": "5O9AM7T0WnkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### e)"
      ],
      "metadata": {
        "id": "DLfSJrlpXwBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The side of the hypercube is given by the following formula:\n",
        "\n",
        "$s=0.1^{\\frac{1}{p}}$\n",
        "\n"
      ],
      "metadata": {
        "id": "9kzfe9dUXx0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5"
      ],
      "metadata": {
        "id": "oJgBdZcCYzvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a)"
      ],
      "metadata": {
        "id": "76piex4dY01v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the decision boundary is linear, we expect the LDA to perform better on a test set, but the QDA may perform better on a training set, since it will be more likely to catch part of the irreducible error."
      ],
      "metadata": {
        "id": "oNEsDw3PY5Dp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b)"
      ],
      "metadata": {
        "id": "OxXBaELyZci2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the decision boundary is non-linear, we expect QDA to perform better on both sets, since LDA is not very flexible and has a larger bias."
      ],
      "metadata": {
        "id": "ca35fbPmZe0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c)"
      ],
      "metadata": {
        "id": "qSswHFiWZ8Nm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the sample size increases in comparison to the number of predictors, QDA tends to perform better, since it has a lower bias and its variance will be less likely to deteriorate the performance due to the larger number of observations used."
      ],
      "metadata": {
        "id": "895fFM21Z9am"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d)"
      ],
      "metadata": {
        "id": "3q8k6VAtauSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the sample size is not very large, the number of parameters to be estimated will provoke a high variance. Therefore, QDA tends to perform poorly in comparison to LDA."
      ],
      "metadata": {
        "id": "BNbo_Wxiavzv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6"
      ],
      "metadata": {
        "id": "PJtjfa_8bcxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a)"
      ],
      "metadata": {
        "id": "6qRYW3jGbeLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "b0=-6\n",
        "b1=0.05\n",
        "b2=1\n",
        "\n",
        "a=math.exp(b0+b1*40+b2*3.5)\n",
        "p=a/(1+a)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erxLEonBbfW_",
        "outputId": "2119de7c-cc79-4147-c5f7-065454c0d19f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.37754066879814546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b)"
      ],
      "metadata": {
        "id": "QEZTAFdBcIDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h=(-b2*3.5-b0)/b1\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyymBMLucJ4P",
        "outputId": "cacbaded-bdbc-4a8f-e0c5-7deb7c925b5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=math.exp(b0+b1*50+b2*3.5)\n",
        "p=a/(1+a)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biLFcovwcrzo",
        "outputId": "ac92f032-c432-43e3-a784-ccdb5206d873"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 7"
      ],
      "metadata": {
        "id": "wXv36fbsgEG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pi_yes = 0.8\n",
        "pi_no = 0.2\n",
        "mu_yes = 10\n",
        "mu_no = 0\n",
        "sigma2=36\n",
        "x = 4\n",
        "\n",
        "f_yes = (1/math.sqrt(2*math.pi*sigma2))*math.exp(-(x-mu_yes)**2/(2*sigma2))\n",
        "f_no = (1/math.sqrt(2*math.pi*sigma2))*math.exp(-(x-mu_no)**2/(2*sigma2))\n",
        "\n",
        "p = (pi_yes*f_yes)/(pi_yes*f_yes+pi_no*f_no)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGCPn2f2gVap",
        "outputId": "459df239-fadc-431f-deb8-f8556b179db0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7518524532975261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 8"
      ],
      "metadata": {
        "id": "rVaa_9_kh8kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since KNN with K=1 has a training error of zero, we can conclude that its test error is 36%. Therefore, the logistic regression performance is better on the test set and it should be choosed for new predictions."
      ],
      "metadata": {
        "id": "eDLJ4Kc3h_Ap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 9"
      ],
      "metadata": {
        "id": "ZfI5VuhFiWCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a)"
      ],
      "metadata": {
        "id": "vOqGBckDiYa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p=0.37/1.37\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxcz-NVbibKY",
        "outputId": "ad619600-41a2-4b62-864a-7786aed517ce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27007299270072993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b)"
      ],
      "metadata": {
        "id": "yqlsKFF6jJAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p=0.16/1.16\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBs61T9ujIvw",
        "outputId": "1c617b5d-4001-48fc-ac1a-7e8cdff0a0f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13793103448275865\n"
          ]
        }
      ]
    }
  ]
}